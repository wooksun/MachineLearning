{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe28153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "import tensorflow.compat.v1 as tf # tensolflow 1.x 버전을 사용한다.\n",
    "tf.disable_v2_behavior() # tensorflow 2.x 버전의 문법을 사용하지 않겠다고 선언한다. => 1.x 버전을 사용할 시에 코딩\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2ca585",
   "metadata": {},
   "source": [
    "공부 시간, 과외 시간과 시험 성적 사이의 관계는 좌표로 나타났을 때 형태가 직선으로 해결되는 선형 회귀를 사용하시에 적합했었다.  \n",
    "공부 시간에 따른 시험 점수가 아닌 합격 여부로 발표되는 시험이 있을 경우 직선으로 해결하기에는 적합하지 못한 문제가 발생된다.  \n",
    "이럴때 사용하는 로지스틱 회귀는 참과 거짓 중에 하나를 내놓는 과정으로 참과 거짓을 구분한 'S'자를 눕혀놓은 형태의 선을 그어주는 작업이다.  \n",
    "<img src=\"./images/sig.png\" align=\"left\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6170965b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부 시간: [2, 4, 6, 8, 10, 12, 14], 합격 여부: [0, 0, 0, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "data = [[2, 0], [4, 0], [6, 0], [8, 1], [10, 1], [12, 1], [14, 1]] # [x(공부 시간), y(합격 여부)]\n",
    "x = [i[0] for i in data] # 공부 시간\n",
    "y = [i[1] for i in data] # 합격 여부, 실제값\n",
    "print('공부 시간: {}, 합격 여부: {}'.format(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ee4e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [0.46428182] b = [0.42681941]\n"
     ]
    }
   ],
   "source": [
    "# 기울기 a와 y절편 b를 임의로 정한다.\n",
    "a = tf.Variable(tf.random_uniform([1], dtype=tf.float64)) \n",
    "b = tf.Variable(tf.random_uniform([1], dtype=tf.float64)) \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print('a = {} b = {}'.format(sess.run(a), sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66893359",
   "metadata": {},
   "source": [
    "시그모이드 방정식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb4dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.e : 넘파이에서 지수 값(2.718281828459045)을 의미하는 상수\n",
    "#print(np.e)\n",
    "Y = 1 / (1 + np.e ** -(a * x + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5fe957",
   "metadata": {},
   "source": [
    "시그모이드 방정식의 오차를 계산하는 수식을 만든다.  \n",
    "시그모이드 함수의 특성은 예측값(Y)이 항상 0 아니면 1이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a8dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -tf.reduce_mean(np.array(y) * tf.log(Y) + (1 - np.array(y)) * tf.log(1 - Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1da1b5",
   "metadata": {},
   "source": [
    "오차를 최소로 하는 값을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2d6b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gratident_descent = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f110e7",
   "metadata": {},
   "source": [
    "학습 시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b549172",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:      0, loss:  0.9475, a:  0.4012, b:  0.4484\n",
      "epoch:   5000, loss:  0.0583, a:  1.5559, b: -10.7028\n",
      "epoch:  10000, loss:  0.0371, a:  2.0084, b: -13.8925\n",
      "epoch:  15000, loss:  0.0274, a:  2.3171, b: -16.0618\n",
      "epoch:  20000, loss:  0.0218, a:  2.5541, b: -17.7247\n",
      "epoch:  25000, loss:  0.0180, a:  2.7468, b: -19.0761\n",
      "epoch:  30000, loss:  0.0154, a:  2.9092, b: -20.2148\n",
      "epoch:  35000, loss:  0.0134, a:  3.0496, b: -21.1986\n",
      "epoch:  40000, loss:  0.0119, a:  3.1731, b: -22.0645\n",
      "epoch:  45000, loss:  0.0106, a:  3.2835, b: -22.8376\n",
      "epoch:  50000, loss:  0.0096, a:  3.3831, b: -23.5356\n",
      "epoch:  55000, loss:  0.0088, a:  3.4739, b: -24.1719\n",
      "epoch:  60000, loss:  0.0081, a:  3.5574, b: -24.7563\n",
      "epoch:  65000, loss:  0.0075, a:  3.6345, b: -25.2967\n",
      "epoch:  70000, loss:  0.0070, a:  3.7062, b: -25.7991\n",
      "epoch:  75000, loss:  0.0066, a:  3.7733, b: -26.2685\n",
      "epoch:  80000, loss:  0.0062, a:  3.8362, b: -26.7090\n",
      "epoch:  85000, loss:  0.0058, a:  3.8954, b: -27.1239\n",
      "epoch:  90000, loss:  0.0055, a:  3.9514, b: -27.5159\n",
      "epoch:  95000, loss:  0.0052, a:  4.0044, b: -27.8874\n",
      "epoch: 100000, loss:  0.0050, a:  4.0549, b: -28.2406\n",
      "epoch: 105000, loss:  0.0047, a:  4.1029, b: -28.5770\n",
      "epoch: 110000, loss:  0.0045, a:  4.1488, b: -28.8982\n",
      "epoch: 115000, loss:  0.0043, a:  4.1927, b: -29.2055\n",
      "epoch: 120000, loss:  0.0042, a:  4.2347, b: -29.5001\n",
      "epoch: 125000, loss:  0.0040, a:  4.2751, b: -29.7829\n",
      "epoch: 130000, loss:  0.0038, a:  4.3140, b: -30.0548\n",
      "epoch: 135000, loss:  0.0037, a:  4.3514, b: -30.3168\n",
      "epoch: 140000, loss:  0.0036, a:  4.3874, b: -30.5693\n",
      "epoch: 145000, loss:  0.0034, a:  4.4223, b: -30.8132\n",
      "epoch: 150000, loss:  0.0033, a:  4.4559, b: -31.0490\n",
      "epoch: 155000, loss:  0.0032, a:  4.4885, b: -31.2771\n",
      "epoch: 160000, loss:  0.0031, a:  4.5201, b: -31.4982\n",
      "epoch: 165000, loss:  0.0030, a:  4.5507, b: -31.7125\n",
      "epoch: 170000, loss:  0.0029, a:  4.5804, b: -31.9205\n",
      "epoch: 175000, loss:  0.0029, a:  4.6093, b: -32.1226\n",
      "epoch: 180000, loss:  0.0028, a:  4.6373, b: -32.3191\n",
      "epoch: 185000, loss:  0.0027, a:  4.6646, b: -32.5102\n",
      "epoch: 190000, loss:  0.0026, a:  4.6912, b: -32.6963\n",
      "epoch: 195000, loss:  0.0026, a:  4.7171, b: -32.8777\n",
      "epoch: 200000, loss:  0.0025, a:  4.7424, b: -33.0545\n",
      "epoch: 205000, loss:  0.0024, a:  4.7670, b: -33.2269\n",
      "epoch: 210000, loss:  0.0024, a:  4.7911, b: -33.3953\n",
      "epoch: 215000, loss:  0.0023, a:  4.8145, b: -33.5597\n",
      "epoch: 220000, loss:  0.0023, a:  4.8375, b: -33.7204\n",
      "epoch: 225000, loss:  0.0022, a:  4.8599, b: -33.8775\n",
      "epoch: 230000, loss:  0.0022, a:  4.8819, b: -34.0312\n",
      "epoch: 235000, loss:  0.0021, a:  4.9034, b: -34.1816\n",
      "epoch: 240000, loss:  0.0021, a:  4.9244, b: -34.3289\n",
      "epoch: 245000, loss:  0.0020, a:  4.9450, b: -34.4731\n",
      "epoch: 250000, loss:  0.0020, a:  4.9652, b: -34.6145\n",
      "epoch: 255000, loss:  0.0020, a:  4.9850, b: -34.7531\n",
      "epoch: 260000, loss:  0.0019, a:  5.0044, b: -34.8890\n",
      "epoch: 265000, loss:  0.0019, a:  5.0235, b: -35.0223\n",
      "epoch: 270000, loss:  0.0019, a:  5.0422, b: -35.1532\n",
      "epoch: 275000, loss:  0.0018, a:  5.0605, b: -35.2817\n",
      "epoch: 280000, loss:  0.0018, a:  5.0785, b: -35.4078\n",
      "epoch: 285000, loss:  0.0018, a:  5.0962, b: -35.5318\n",
      "epoch: 290000, loss:  0.0017, a:  5.1136, b: -35.6536\n",
      "epoch: 295000, loss:  0.0017, a:  5.1307, b: -35.7733\n",
      "epoch: 300000, loss:  0.0017, a:  5.1475, b: -35.8911\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(300001):\n",
    "    sess.run(gratident_descent)\n",
    "    if epoch % 5000 == 0:\n",
    "        print('epoch: {:6d}, loss: {:7.4f}, a: {:7.4f}, b: {:7.4f}'.format(epoch, sess.run(loss), sess.run(a)[0], sess.run(b)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b867fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26faf035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1cfc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a261b09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c35252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
