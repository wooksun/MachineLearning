{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156056ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e10858",
   "metadata": {},
   "source": [
    "CNN(Convolutional Neural Network) - 합성곱 신경망\n",
    "\n",
    "데이터 획득  \n",
    "MNIST 데이터를 내려받아 학습 데이터 및 테스트 데이터로 분리해서 저장한다.  \n",
    "MNIST 데이터는 28 * 28의 픽셀 데이터로 각 픽셀은 흑백 사진과 같이 0부터 255 사이의 그레이스케일을 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3368ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a133bae6",
   "metadata": {},
   "source": [
    "학습 데이터에서 검증 데이터 분리하기  \n",
    "학습 중간마다 검증 데이터로 모델의 성능을 측정하면 모델 학습이 제대로 진행되는지 검증 정확도를 확인할 수 있고, 학습 정확도는 증가하는데 검증 정확도가 증가하지 않거나 떨어질 때 조기 종료를 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fa74960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6만 개의 학습 데이터 중에서 1만 개의 학습 데이터를 검정 데이터로 따로 저장한다.\n",
    "x_val = x_train[50000:] # 학습 데이터 6만개 중에서 학습 결과 검증에 사용할 데이터 1만개\n",
    "x_train = x_train[:50000] # 학습 데이터 6만개 중에서 학습에 사용할 데이터 5만개\n",
    "y_val = y_train[50000:] # 검증 데이터 실제값\n",
    "y_train = y_train[:50000] # 학습 데이터 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aa35356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터: (50000, 28, 28)\n",
      "검증 데이터: (10000, 28, 28)\n",
      "테스트 데이터: (10000, 28, 28)\n",
      "================================================================================\n",
      "학습 데이터 레이블: (50000,)\n",
      "검증 데이터 레이블: (10000,)\n",
      "테스트 데이터 레이블: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('학습 데이터: {}'.format(x_train.shape)) # 학습 데이터는 5만 개이고 28 * 28 픽셀의 이미지이다.\n",
    "print('검증 데이터: {}'.format(x_val.shape)) # 검증 데이터는 1만 개이고 28 * 28 픽셀의 이미지이다.\n",
    "print('테스트 데이터: {}'.format(x_test.shape)) # 테스트 데이터는 1만 개이고 28 * 28 픽셀의 이미지이다.\n",
    "print('=' * 80)\n",
    "print('학습 데이터 레이블: {}'.format(y_train.shape))\n",
    "print('검증 데이터 레이블: {}'.format(y_val.shape))\n",
    "print('테스트 데이터 레이블: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3020e8",
   "metadata": {},
   "source": [
    "학습 데이터를 출력해보면 데이터가 0부터 255사이의 숫자(그레이스케일)로 구성된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a222598c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13  25 100 122   7   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0  33 151 208 252 252 252 146   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0  40 152 244 252 253 224 211 252 232  40   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  15 152 239 252 252 252 216  31  37 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  96 252 252 252 252 217  29   0  37 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0 181 252 252 220 167  30   0   0  77 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  26 128  58  22   0   0   0   0 100 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 157 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0 110 121 122 121 202 252 194   3   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0  10  53 179 253 253 255 253 253 228  35   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   5  54 227 252 243 228 170 242 252 252 231 117   6   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   6  78 252 252 125  59   0  18 208 252 252 252 252  87   7   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   5 135 252 252 180  16   0  21 203 253 247 129 173 252 252 184  66  49  49   0   0   0 \n",
      "  0   0   0   0   0   3 136 252 241 106  17   0  53 200 252 216  65   0  14  72 163 241 252 252 223   0   0   0 \n",
      "  0   0   0   0   0 105 252 242  88  18  73 170 244 252 126  29   0   0   0   0   0  89 180 180  37   0   0   0 \n",
      "  0   0   0   0   0 231 252 245 205 216 252 252 252 124   3   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0 207 252 252 252 252 178 116  36   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0  13  93 143 121  23   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])\n",
    "for i in x_train[5]:\n",
    "    for j in i:\n",
    "        print('{:3d} '.format(j), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683e591",
   "metadata": {},
   "source": [
    "컴퓨터 비전에서 많이 사용되는 딥러닝 모델인 CNN의 장점은 다층 퍼솁트론과 비교하면 쉽게 이해할 수 있다.\n",
    "\n",
    "다층 퍼셉트론의 첫 번째 단점은 고유 이미지의 생심새를 사용할 수 없다는 것이다.  \n",
    "다층 퍼셉트론의 경우 데이터를 입력하기 위해서 2차원 평면에 있는 숫자를 1차원 배열로 변환해야 한다. 1차원 배열로 변환된 데이터는 원래 고유 숫자 이미지를 떠올리기 쉽지 않다.  \n",
    "1차원으로 변환된 데이터를 입력으로 받는 다층 퍼셉트론의 경우, 고유 데이터가 2차원 평면에서 가지고 있던 지역 정보를 잃어버린 채로 삭습을 시작한다.  \n",
    "\n",
    "두 번째 단점은 다층 퍼셉트론은 픽셀 하나 하나의 변화에 상당히 민감하다는 것이다.  \n",
    "이미지의 생김새 정보를 사용할 수 없는 다층 퍼셉트론은 가지고 있는 정보가 픽셀 정보밖에 없기 떄문에 픽셀 한두 개의 차이가 모델 예측에 큰 영향을 끼치게 된다.  \n",
    "\n",
    "세 번째 단점은 다층 퍼셉트론은 픽셀 한두 개의 정보에도 민감하게 반응하기 위해 상당히 많은 변수를 모델 안에 가지고 있다는 것이다. 이로 인해 모델의 크기를 크게 만들고,  \n",
    "학습 시간이 오래 걸리며, 자칫 잘못하면 과대 적합된 모델이 되기 쉽다.\n",
    "\n",
    "<img src=\"./images/CNN.png\" align=\"left\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce71c330",
   "metadata": {},
   "source": [
    "두 개의 비슷한 생김새의 숫자 2가 있을 때 생김새가 달라도 머리와 꼬리 부분이 있고 머리와 꼬리를 잇는 대각선이 있다면 단번에 숫자 2임을 판별할 수 있다. \n",
    "\n",
    "CNN은 어떻게 특징을 찾아내는가?  \n",
    "<img src=\"./images/CNN2.png\" align=\"left\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5abe42",
   "metadata": {},
   "source": [
    "위 그림에서 필터 또는 커널이라고 불리는 반투명한 네모 상자가 이미지 왼쪽 상단에서 조금씩 이동하면서 오른쪽 최하단까지 이동한다.  \n",
    "이처럼 필터를 이동하는 기법을 스트라이드(stride)라고 한다.  \n",
    "필터는 특징을 추출하기 위한 네모 상자이고, 이 필터와 겹치는 이미지 부분을 수용 영역이라 부른다.  \n",
    "\n",
    "아래 그림에서 대각선 필터는 숫자 2로부터 두 곳의 대각선 특징을 감지한다. 하지만 숫자 1에서는 대각선 특징을 발견하지 못한다.\n",
    "<img src=\"./images/CNN3.png\" align=\"left\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c606f",
   "metadata": {},
   "source": [
    "모든 딥러닝 모델이 그렇듯이 CNN 모델 역시 수학적인 모델이다. 필터가 어떻게 특징을 추출해내는지 알아보자.  \n",
    "MNIST 숫자 데이터는 흑백 이미지로 각 픽셀은 0부터 255 사이의 값 중 하나를 가지고 있다. 픽셀 안의 숫자 0은 흰색을 의미하며 255는 검은색을 그리고 그 사이의 숫자는 흰색과  \n",
    "검은색 사이의 어떤 색(회색)을 의미한다.  \n",
    "만약 이미지 안에 흰색과 검은색만 존재한다면 아래 그림과 같이 0과 255로만 구성되어 있을 것이다.\n",
    "\n",
    "<img src=\"./images/CNN4.png\" align=\"left\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346e14b",
   "metadata": {},
   "source": [
    "위 그림에서 알 수 있듯이 필터 안에는 특정한 숫자가 들어있고, 필터와 이미지 영역의 겹치는 부분마다 곱셈이 이루어지고 필터에 4개의 픽셀이 있으면 4개의 영역이 곱해지고,  \n",
    "곱해진 값은 최종적으로 더해진다.  \n",
    "최종값이 크다는 의미는 필터와 겹쳐진 부분이 많다는 의미이며 반대로 최종값이 작을 경우 필터와 겹치는 부분이 적었다라고 해석을 할 수 있다.\n",
    "\n",
    "CNN 모델 안에는 각 특성의 개수만큼 필터가 필요하다.  \n",
    "보통 전반부 레이어에 존재하는 필터는 직선, 곡선 같은 기초적인 특성을 구별하기 위해 존재하고 후반부에 있는 필터는 동그라미, 세모 같은 조금 더 고차원의 특징을 구별하기 위해 존재한다.  \n",
    "필터를 사용해서 모든 특징을 찾아낸 후, 이 특징들은 다중 퍼셉트론의 입력값으로 들어가서 필터로 부터 구별된 특징을 기반으로 숫자 분류를 진행한다.\n",
    "<img src=\"./images/CNN5.png\" align=\"left\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7ea39d",
   "metadata": {},
   "source": [
    "스트라이드(스프라이트 X)를 통해 얻어진 행렬을 피쳐 맵(feature map)이라고 한다.  \n",
    "피처 맵을 활성화 함수에 넣어 구현한 행렬을 액티베이션 맵(activation map)이라고 한다.\n",
    "\n",
    "맥스 풀링(max pooling)은 지정된 영역에서 가장 큰 수치를 선택하고 나머지는 버린다.  \n",
    "아래 그림은 2 * 2 필터에 스트라이드를 적용한 피쳐 맵에 맥스 풀링을 적용한 예이다.  \n",
    "피쳐 맵의 크기가 줄어듬으로써 얻는 장점은 계산에 사용되는 파라미터의 개수가 줄어들어 계산 속도가 빨라지고, 파라미터를 줄임으로써 모델의 분산을 줄이고,  \n",
    "그에따라 과대 적합의 가능성을 줄여준다.\n",
    "\n",
    "<img src=\"./images/CNN6.png\" align=\"left\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab18dc92",
   "metadata": {},
   "source": [
    "제로 패딩(zero padding)은 0으로 입력 행렬의 테두리를 감싸는 기술이다.  \n",
    "스트라이드를 통해 입력된 행렬보다 작아진 행렬이 출력되고 작아진 만큼 정보 손실이 발생되므로 제로 패딩을 통해 입력 행력의 크기를 크게 함으로써 스트라이드 이후에도 이미지 크기를 동일하게 유지할 수 있다.\n",
    "\n",
    "<img src=\"./images/CNN7.png\" align=\"left\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610dd719",
   "metadata": {},
   "source": [
    "제로 패딩으로 인해 스트라이드 할 공간이 더 많아졌다. 만약 필터 크기가 3 * 3이고 스트라이드를 1픽셀씩 할 경우 피쳐 맵은 5 * 5로 제로 패딩을 하기 전의 입력 행력과 동일한 크기로 출력될 것이다. \n",
    "\n",
    "데이터 구조 변경하기  \n",
    "28 * 28 픽셀의 단색 이미지이므로 데이터 형태를 28 * 28 * 1로 맞춰준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fb5b5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (50000, 28, 28, 1)\n",
      "x_val.shape: (10000, 28, 28, 1)\n",
      "x_test.shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# CNN 모델에 입력하기 위해 데이터셋을 생성한다.\n",
    "x_train = np.reshape(x_train, [50000, 28, 28, 1])\n",
    "print('x_train.shape: {}'.format(x_train.shape))\n",
    "x_val = np.reshape(x_val, [10000, 28, 28, 1])\n",
    "print('x_val.shape: {}'.format(x_val.shape))\n",
    "x_test = np.reshape(x_test, [10000, 28, 28, 1])\n",
    "print('x_test.shape: {}'.format(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff428fd",
   "metadata": {},
   "source": [
    "데이터 정규화  \n",
    "데이터 정규화는 학습 시간을 단축하고, 더 나은 성능을 발휘하도록 도와준다.  \n",
    "MNIST 데이터의 모든 값은 0부터 255 사이의 범위 안에 있으므로 255로 나눠줌으로써 모든 값을 0부터 1사이의 값으로 정규화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0da6547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_val /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39fd5be",
   "metadata": {},
   "source": [
    "실제값을 원-핫 인코딩으로 변경하기  \n",
    "손실 함수에서 크로스 엔트로피를 계산하기 위해 실제값을 원-핫 인코딩으로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bbf2b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes) # 학습 데이터 실제값 원-핫 인코딩\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes) # 검증 데이터 실제값 원-핫 인코딩\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) # 테스트 데이터 실제값 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18263f87",
   "metadata": {},
   "source": [
    "텐서플로우로 CNN 구현하기\n",
    "\n",
    "<img src=\"./images/CNN8.png\" align=\"left\" width=\"1100\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33c15abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 데이터 형태 그대로 28 * 28의 포맷을 입력 데이터로 사용하고, 실제값은 0부터 9사이의 숫자이다.\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1]) # 학습 데이터\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 10]) # 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fadc7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.random_normal()와 truncated_normal()는 매우 비슷하게 작동하지만 큰 차이가 있다.\n",
    "# 두 메소드 모두 랜덤하게 값을 가져오는데 두 방식의 가장 큰 차이는 truncated_normal() 메소드는 너무 작거나 너무 큰 값이 아닌 값으로 랜덤하게 가져온다.\n",
    "# 딥러닝이나 머신러닝 중 너무 큰 기울기(기울기 폭주) 값이나 너무 작은 기울기(기울기 소멸) 값이 들어오면 작동을 멈춰버리는 현상이 발생되는데, \n",
    "# 이를 해결하기 위한 방법으로 truncated_normal() 메소드를 사용해서 난수를 발생시켜 사용한다.\n",
    "import matplotlib.pyplot as plt\n",
    "n = 100000\n",
    "A = tf.random_normal((n,))\n",
    "B = tf. truncated_normal((n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31bbd7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    a = sess.run(A)\n",
    "    plt.hist(a, 1000, (-4.5, 4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1196261a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    b = sess.run(B)\n",
    "    plt.hist(b, 1000, (-4.5, 4.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97618a1b",
   "metadata": {},
   "source": [
    "파라미터(가중치, 바이어스)의 초기값을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fccbc903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncated_normal() 메소드는 0에서 거리가 아주 먼 값이 설정되지 않게 도와준다.\n",
    "# 0에서 거리가 먼 값을 제외시키는 이유는 소프트 맥스 안의 시그모이드 함수의 특성 때문인데, 시그모이드 함수 같은 경우 입력값이 매우 크거나 작으면 그 미분값이\n",
    "# 0과 가까워져서 경사 하강법으로 파라미터를 변경하기 어려워진다.\n",
    "\n",
    "# 가중치를 만들어 리턴하는 함수\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1) # stddev 속성으로 난수가 발생되는 범위를 설정한다.\n",
    "    return tf.Variable(initial)\n",
    "    \n",
    "# 바이어스를 만들어 리턴하는 함수\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d58eb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07907945]\n",
      " [0.09941635]] [0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    w = weight_variable([2, 1])\n",
    "    b = bias_variable([2])\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(w), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "275bd4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필터를 적용할 이미지 데이터와 필터를 넘겨받아 컨볼루션 레이어를 만들어 리턴하는 함수\n",
    "# conv2d(필터를 적용할 이미지 데이터, 필터, strides, padding) 메소드는 이미지 데이터에 필터를 스트라이드(strides)만큼 적용한다.\n",
    "# strides: 필터가 움직이는 간격으로 첫번째 값과 4번째 값은 통상적으로 1을 사용하고 2번쨰 값은 가로 스트라이드 값, \n",
    "#          3번째 값은 세로 스트라이드 값을 입력한다.\n",
    "# padding: 입력 데이터 행렬 주위를 무의미한 값(0)으로 감싸사 필터를 거쳐 나온 피쳐 맵의 크기가 작아지는 것을 방지하고\n",
    "#          과대 적합이 발생하는 것을 방지할 수 있다.\n",
    "#          => SAME: 텐서플로우가 자동으로 패딩을 적용해 입력값과 출력값의 크기를 같게한다.\n",
    "#          => VALID: 텐서플로우가 자동으로 패딩을 적용하지 않아 입력값 보다 출력값의 크기가 작아진다. 패딩 미적용\n",
    "def conv2d(x, W_conv):\n",
    "    return tf.nn.conv2d(x, W_conv, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# 맥스 풀링을 실행하는 함수\n",
    "# max_pool(활성화 함수로 ReLu를 적용하고 맥스 풀링을 적용할 데이터, ksize, strides, padding) 메소드는 맥스 풀링을 적용한다.\n",
    "# ksize: 맥스 풀링의 크기로 [1, 2, 2, 1]는 2 * 2 크기로 묶어서 맥스 풀링을 한다는 의미이다.\n",
    "# strides, padding은 conv2d() 메소드와 의미가 같다.\n",
    "# ksize, strides는 모두 필터의 크기를 의미하므로 동일한 값으로 지정해야 한다.\n",
    "def max_pool_2x2(h_conv):\n",
    "    return tf.nn.max_pool(h_conv, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4f272e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 컨볼루션 레이어는 16개의 필터를 가지고 있고, 필터 크기는 5 * 5이고 바이어스는 필터(출력)의 개수 만큼 만든다.\n",
    "W_conv1 = weight_variable([5, 5, 1, 16]) # 1번째 컨볼루션 레이어의 필터 정의\n",
    "b_conv1 = bias_variable([16]) # 1번째 컨볼루션 레이어의 바이어스\n",
    "\n",
    "# 활성화 함수로 ReLu를 사용한다.\n",
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)\n",
    "\n",
    "# 1번째 컨볼루션 레이어의 출력에 풀링 레이어를 적용해서 액티베이션 맵의 크기를 줄여준다.\n",
    "# 액티베이션 맵의 크기를 줄여줌으로써 파라미터가 줄어들어 모델의 크기가 작아지고 과대 적합의 위험도 감소시켜 준다.\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# 폴링 레이어에 의해 액티베이션 맵의 크기가 14 * 14가 되었고 이 값은 다음에 이어지는 2번째 컨볼루션 레이어의 입력으로 들어간다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c968993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2번째 컨볼루션 레이어는 32개의 필터를 가진다.\n",
    "W_conv2 = weight_variable([5, 5, 16, 32]) # 2번째 컨볼루션 레이어의 필터 정의\n",
    "b_conv2 = bias_variable([32]) # 2번째 컨볼루션 레이어의 바이어스\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "# 풀링 레이어에 의해 액티베이션 맵의 크기는 7 * 7이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c3c830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FC(Fully Connected Layer)\n",
    "# FC 영역에는 FC1, FC2 총 2개의 히든 레이어가 존재하고 FC1은 128개의 노드, FC2는 10개의 노드가 존재한다.\n",
    "# FC2에 10개의 노드가 존재하는 이유는 FC2의 10개 노드의 값들을 소프트 맥스에 입력해서 각 노드별 확률을 구하기 위해서이다.\n",
    "# 각 노드는 숫자 0부터 9를 의미하며, 이 예측값은 크로스 엔트로피를 통해 실제값과의 차이를 계산하는데 사용된다.\n",
    "\n",
    "# FC는 컨볼루션 레이어를 통해 추출된 이미지의 특징을 입력받아 0부터 9사이의 숫자 중 하나로 이미지를 분류한다.\n",
    "W_fc1 = weight_variable([7 * 7 * 32, 128])\n",
    "b_fc1 = bias_variable([128])\n",
    "\n",
    "# 2번째 컨볼루션 레이어의 맥스 풀링 결과를 행과 열을 변경해서 가중치와 행렬의 곱을 이용해 계산하고 활성화 함수로 ReLu를 사용한다.\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 32])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "W_fc2 = weight_variable([128, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f7eb46",
   "metadata": {},
   "source": [
    "오차 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b98ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의가 끝났으므로 모델을 학습시키기 위해서 손실 함수를 정의한다. 손실 함수로는 크로스 엔트로피를 사용한다.\n",
    "# 실제값과 예측값의 크로스 엔트로피를 설정한다.\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_conv, labels=y)\n",
    ")\n",
    "# Adam 옵티마이저를 사용해 모델을 최적화 한다.\n",
    "train = tf.train.AdamOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e62c9c",
   "metadata": {},
   "source": [
    "정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80d849f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(predict, 'float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34762d4",
   "metadata": {},
   "source": [
    "학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "630f8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:   0, 학습 정확도: 0.1360\n",
      "step:  10, 학습 정확도: 0.6400\n",
      "step:  20, 학습 정확도: 0.7940\n",
      "step:  30, 학습 정확도: 0.8760\n",
      "step:  40, 학습 정확도: 0.9060\n",
      "step:  50, 학습 정확도: 0.9320\n",
      "step:  60, 학습 정확도: 0.9420\n",
      "step:  70, 학습 정확도: 0.9420\n",
      "step:  80, 학습 정확도: 0.9680\n",
      "step:  90, 학습 정확도: 0.9620\n",
      "epoch: 1, 검증 정확도: 0.9687\n",
      "================================================================================\n",
      "step:   0, 학습 정확도: 0.9580\n",
      "step:  10, 학습 정확도: 0.9680\n",
      "step:  20, 학습 정확도: 0.9660\n",
      "step:  30, 학습 정확도: 0.9680\n",
      "step:  40, 학습 정확도: 0.9640\n",
      "step:  50, 학습 정확도: 0.9680\n",
      "step:  60, 학습 정확도: 0.9720\n",
      "step:  70, 학습 정확도: 0.9720\n",
      "step:  80, 학습 정확도: 0.9860\n",
      "step:  90, 학습 정확도: 0.9800\n",
      "epoch: 2, 검증 정확도: 0.9772\n",
      "================================================================================\n",
      "step:   0, 학습 정확도: 0.9780\n",
      "step:  10, 학습 정확도: 0.9820\n",
      "step:  20, 학습 정확도: 0.9660\n",
      "step:  30, 학습 정확도: 0.9740\n",
      "step:  40, 학습 정확도: 0.9760\n",
      "step:  50, 학습 정확도: 0.9780\n",
      "step:  60, 학습 정확도: 0.9780\n",
      "step:  70, 학습 정확도: 0.9740\n",
      "step:  80, 학습 정확도: 0.9880\n",
      "step:  90, 학습 정확도: 0.9880\n",
      "epoch: 3, 검증 정확도: 0.9809\n",
      "================================================================================\n",
      "최종 모델 테스트 정확도: 0.9812\n"
     ]
    }
   ],
   "source": [
    "# 미니 배치를 사용해서 모델을 최적화 한다.\n",
    "# 하이퍼 파라미터 설정\n",
    "epoch_cnt = 3\n",
    "batch_size = 500\n",
    "iteration = len(x_train) // batch_size\n",
    "\n",
    "# 학습 시작\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            if i % 10 == 0:\n",
    "                train_acc = accuracy.eval(feed_dict={x: x_train[start:end], y: y_train[start:end]})\n",
    "                print('step: {:3d}, 학습 정확도: {:6.4f}'.format(i, train_acc))\n",
    "            # ===== if\n",
    "            # Adam 옵티마이저를 사용한 최적화 함수를 실행한다.\n",
    "            train.run(feed_dict={x: x_train[start:end], y: y_train[start:end]})\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "        # ===== for i \n",
    "        \n",
    "        # 검증 데이터로 모델을 검증한다.\n",
    "        val_accuracy = accuracy.eval(feed_dict={x: x_val, y: y_val})\n",
    "        print('epoch: {}, 검증 정확도: {:6.4f}'.format(epoch + 1, val_accuracy))\n",
    "        print('=' * 80)\n",
    "        \n",
    "    # ===== for epoch\n",
    "    # 모델을 테스트 데이터로 테스트한 정확도를 계산해서 출력한다.\n",
    "    test_accuracy = accuracy.eval(feed_dict={x: x_test, y: y_test})\n",
    "    print('최종 모델 테스트 정확도: {:6.4f}'.format(test_accuracy))\n",
    "# ===== with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132cd4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ef903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a51762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492b0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae9055d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc85e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c314b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06b78a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950fd425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e1648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1b045e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
