{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f75ed67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config Completer.use_jedi = False\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6207e",
   "metadata": {},
   "source": [
    "<img src=\"./images/MNIST1.png\" align=\"left\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d2f8d6",
   "metadata": {},
   "source": [
    "MNIST 손글씨 실습을 위해서 케라스에서 제공하는 MNIST 데이터 셋을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72a551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc214ed",
   "metadata": {},
   "source": [
    "학습 데이터에는 총 60,000개의 샘플 데이터가 있고, 테스트 데이터에는 총 10,000개의 샘플 데이터가 있다.  \n",
    "MNIST 데이터는 이미지 하나가 28개의 행과 28개의 열을 갖는 픽셀 데이터이다. 각 픽셀은 흑백 사진과 같이 0부터 255까지의 그레이스케일을 가지고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a752d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (60000, 28, 28), y_train.shape: (60000,)\n",
      "x_test.shape: (10000, 28, 28), y_test.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train.shape: {}, y_train.shape: {}'.format(x_train.shape, y_train.shape)) # 학습데이터\n",
    "print('x_test.shape: {}, y_test.shape: {}'.format(x_test.shape, y_test.shape)) # 테스트 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba006a1a",
   "metadata": {},
   "source": [
    "학습 데이터를 학습 데이터(5만개)와 검증 데이터(1만개)로 분리한다.  \n",
    "학습 중간마다 검증 데이터로 모델 성능을 측정하면 모델 학습이 제대로 진행되는지 검증 정확도를 알 수 있고, 학습 정확도는 올라가는데 검증 정확도가 더 이상 올라가지 않거나  \n",
    "떨어질 경우 학습의 조기 종료를 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b123bf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (50000, 28, 28), y_train.shape: (50000,)\n",
      "x_val.shape: (10000, 28, 28), y_val.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터로 사용하기 위해 학습 데이터에서 1만개를 분리한다.\n",
    "x_val = x_train[50000:] # 28행 28열로 구성된 검증 데이터\n",
    "x_train = x_train[:50000] # 28행 28열로 구성된 학습 데이터\n",
    "y_val = y_train[50000:] # 검증 데이터 실제값(레이블, 타겟, 클래스)\n",
    "y_train = y_train[:50000] # 학습 데이터 실제값\n",
    "print('x_train.shape: {}, y_train.shape: {}'.format(x_train.shape, y_train.shape)) # 학습데이터\n",
    "print('x_val.shape: {}, y_val.shape: {}'.format(x_val.shape, y_val.shape)) # 검증 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1191f4d7",
   "metadata": {},
   "source": [
    "학습 데이터를 출력해보면 데이터가 0부터 255사이의 숫자(그레이스케일)로 구성된 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d009d10a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1 4]\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  13  25 100 122   7   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0  33 151 208 252 252 252 146   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0  40 152 244 252 253 224 211 252 232  40   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  15 152 239 252 252 252 216  31  37 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  96 252 252 252 252 217  29   0  37 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0 181 252 252 220 167  30   0   0  77 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  26 128  58  22   0   0   0   0 100 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 157 252 252  60   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0 110 121 122 121 202 252 194   3   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0  10  53 179 253 253 255 253 253 228  35   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   5  54 227 252 243 228 170 242 252 252 231 117   6   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   6  78 252 252 125  59   0  18 208 252 252 252 252  87   7   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   5 135 252 252 180  16   0  21 203 253 247 129 173 252 252 184  66  49  49   0   0   0 \n",
      "  0   0   0   0   0   3 136 252 241 106  17   0  53 200 252 216  65   0  14  72 163 241 252 252 223   0   0   0 \n",
      "  0   0   0   0   0 105 252 242  88  18  73 170 244 252 126  29   0   0   0   0   0  89 180 180  37   0   0   0 \n",
      "  0   0   0   0   0 231 252 245 205 216 252 252 252 124   3   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0 207 252 252 252 252 178 116  36   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0  13  93 143 121  23   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])\n",
    "for i in x_train[5]:\n",
    "    for j in i:\n",
    "        print('{:3d} '.format(j), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41425017",
   "metadata": {},
   "source": [
    "MNIST 데이터를 불러왔으니 다층 퍼셉트론의 입력값으로 들어갈 수 있도록 넘파이의 reshape() 메소드를 사용해서 2차원 배열 형태의 데이터를 1차원 배열 형태로 변경한다.  \n",
    "<img src=\"./images/MNIST3.png\" align=\"left\" width=\"1200\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "765790da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: (50000, 28, 28)\n",
      "x_train.shape: (50000, 784)\n",
      "x_val.shape: (10000, 28, 28)\n",
      "x_test.shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 28 * 28 픽셀의 단색 이미지이므로 데이터 형태를 784개의 1차원 배열 형태로 변환한다.\n",
    "print('x_train.shape: {}'.format(x_train.shape))\n",
    "# x_train = np.reshape(x_train, [50000, 784]) # 28행 28열로 구성된 학습 데이터를 784개의 1차원 배열 형태로 변환한다.\n",
    "x_train = x_train.reshape(50000, 784)\n",
    "print('x_train.shape: {}'.format(x_train.shape))\n",
    "x_train = x_val.reshape(10000, 784) # 28행 28열로 구성된 검증 데이터를 784개의 1차원 배열 형태로 변환한다.\n",
    "print('x_val.shape: {}'.format(x_val.shape))\n",
    "x_train = x_test.reshape(10000, 784) # 28행 28열로 구성된 테스트 데이터를 784개의 1차원 배열 형태로 변환한다.\n",
    "print('x_test.shape: {}'.format(x_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f73f291",
   "metadata": {},
   "source": [
    "1차원으로 변경된 데이터를 그대로 다층 퍼셉트론에 입력해도 되지만 조금 더 효율적인 학습을 위해 데이터를 정규화 시킨다. 정규화는 모덱의 학습 시간을 단축시키고,  \n",
    "더 나은 성능을 보이게 하는 효과가 있다.  \n",
    "MNIST 손글씨 데이터의 모든 값들은 0부터 255 사이의 범위 안에 있으므로 255로 나눠 모든 값들을 0부터 1사이의 값으로 정규화 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcaf2a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(x_train[0][0]), x_train[0][0]) # <class 'numpy.uint8'> 0\n",
    "x_train = x_train.astype('float32')\n",
    "# print(type(x_train[0][0]), x_train[0][0]) # <class 'numpy.float32'> 0.0\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_val /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ceaf404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n"
     ]
    }
   ],
   "source": [
    "print(set(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534669c",
   "metadata": {},
   "source": [
    "MNIST 손글씨 데이터 분류 모델은 0부터 9사이의 숫자로 분류하는 다중 모델이므로 손실함수로 크로스 엔트로피를 사용한다.  \n",
    "크로스 엔트로피를 계산하기 위해 실제값(y_train, y_val, y_test)을 원-핫 인코딩(one-hot encoding)으로 변환한다.  \n",
    "원-핫 인코딩은 데이터를 수많은 0과 1개의 1로 데이터를 구별하는 인코딩 방식으로 0으로 이루어진 벡터 집합에 단 1개의 1의 값으로 해당 데이터를 구별하는 것을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23c1d8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# to_categorical() 메소드로 데이터에 원-핫 인코딩을 적용할 수 있다.\n",
    "num_classes = 10\n",
    "print(y_train[:5])\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "for i in y_train[:5]:\n",
    "    print(i)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604ce19",
   "metadata": {},
   "source": [
    "입력 데이터는 784개의 숫자가 들어있는 1차원 배열이다.  \n",
    "784개의 입력을 받는 256개의 노드가 1번째 히든 레이어에 있고, 1번째 히든 레이어의 출력값을 입력으로 받는 2번째 히든 레이어에는 128개의 노드가 있다.  \n",
    "2번째 히든 레이어에는 과대 적합을 방지하기 위해 10% 드롭 아웃을 적용한다.  \n",
    "3번째 히든 레이어에서는 총 10개의 노드가 존재하며 이 10개의 노드값은 소프트 맥스를 통과해서 0부터 9사이에 해당되는 각 숫자의 확률을 의미한다.  \n",
    "소프트 맥스는 분류해야하는 정답지(레이블, 클래스, 타겟)의 총 개수를 k라고 할 때, k차원의 벡터를 입력받아 각 정답에 대한 확률을 추정한다.  \n",
    "소프트 맥스의 출력값과 실제값의 차이(오차)를 계산하기 위해 크로스 엔트로피를 손실 함수로 사용하고 손실 함수를 최소화 하기 위해서 Adam 옵티마이저(최적화 함수)를 사용해서  \n",
    "역전파를 통해 모든 가중치 및 편향값을 최적화 한다.  \n",
    "\n",
    "최적화 참고 사이트  \n",
    "https://onevision.tistory.com/entry/Optimizer-%EC%9D%98-%EC%A2%85%EB%A5%98%EC%99%80-%ED%8A%B9%EC%84%B1-Momentum-RMSProp-Adam\n",
    "\n",
    "<img src=\"./images/MNIST2.png\" align=\"left\" width=\"900\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbded28",
   "metadata": {},
   "source": [
    "소프트 맥스(Soft Max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5895692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 10  5]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([3, 10, 5]) # 1차원 배열\n",
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "# argmax() 메소드는 배열에서 가장 큰 값을 찾아서 그 인덱스를 리턴한다.\n",
    "# a 배열에서 10이 가장 크기 때문에 결과는 10의 인덱스 1이 출력된다.\n",
    "print(sess.run(tf.argmax(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1f3ab28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3 10  5]\n",
      " [ 4  5  6]\n",
      " [ 0  8  7]]\n",
      "[1 0 2]\n",
      "[1 0 2]\n",
      "[1 2 1]\n"
     ]
    }
   ],
   "source": [
    "b = tf.constant([[3, 10, 5], [4, 5, 6], [0, 8, 7]]) # 2차원 배열\n",
    "print(sess.run(b))\n",
    "# argmax() 메소드를 2차원에서 사용할 경우 2번째 인수를 지정해야 한다. 생략시 기본값은 0\n",
    "# 2번째 인수를 생략하거나 0을 사용하면 2차원 배열의 각 열에서 최대값의 인덱스를 리턴하고 2번째 인수에 1을 쓰면 2차원 배열의 각 행에서 최대값의 인덱스를 리턴한다.\n",
    "# b 배열에서 열 단위로 최대값을 계산하면 0번째 열의 최대값 4의 인덱스 1, 1번째 열의 최대값 10의 인덱스 0, 2번째 열의 최대값 7의 인덱스 2가 [1 0 2]와 같이 출력된다.\n",
    "print(sess.run(tf.argmax(b)))\n",
    "print(sess.run(tf.argmax(b, 0)))\n",
    "# b 배열에서 행 단위로 최대값을 계산하면 0번째 열의 최대값 10의 인덱스 1, 1번째 행의 최대값 6의 인덱스 2, 2번째 행의 최대값 8의 인덱스 1이 [1 2 1]와 같이 출력된다.\n",
    "print(sess.run(tf.argmax(b, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1405ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1번째 차원이 None인 이유는 데이터 개수의 제약없이 입력받기 위해서이고 2번째 차원이 784인 것은 MNIST 손글씨 이미지의 크기가 28 * 28 픽셀 = 784 픽셀이기 떄문이다.\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 784]) # 학습 데이터를 기억한 pleaceholder를 선언한다. \n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 10]) # 실제값을 기억한 placeholder를 선언한다.\n",
    "keep_prob = tf.placeholder(dtype=tf.float32) # 드롭 아웃 적용 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b93ddb8",
   "metadata": {},
   "source": [
    "다층 퍼셉트론을 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29cf76cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x):\n",
    "    # 히든 레이어1\n",
    "    w1 = tf.Variable(tf.random_uniform([784, 256]))\n",
    "    b1 = tf.Variable(tf.zeros([256]))\n",
    "    h1 = tf.nn.relu(tf.matmul(x, w1) + b1)\n",
    "    # 히든 레이어2\n",
    "    w2 = tf.Variable(tf.random_uniform([256, 128]))\n",
    "    b2 = tf.Variable(tf.zeros([128]))\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "    # 드롭 아웃 적용, 예전에는 rate=keep_prob 형태로 사용했었는데 버전이 올라가면서 rate=1-keep_prob와 같은 형태로 사용해야 한다.\n",
    "    h2_drop = tf.nn.dropout(h2, rate=1-keep_prob)\n",
    "    # 히든 레이어3\n",
    "    w3 = tf.Variable(tf.random_uniform([128, 10]))\n",
    "    b3 = tf.Variable(tf.zeros([10]))\n",
    "    logit = tf.nn.relu(tf.matmul(h2_drop, w3) + b3)\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17434af",
   "metadata": {},
   "source": [
    "다층 퍼셉트론의 출력값을 logits(logistic + probit)로 정의한다. probit는 확률을 재는 단위를 의미한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "963deecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = mlp(x)\n",
    "# logit와 실제값의 크로스 엔트로피를 손실 함수로 사용한다.\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit, labels=y)\n",
    ")\n",
    "# Adam 옵티마이저를 사용해 모델을 최적화 한다.\n",
    "# 모델의 최적화 과정은 모델의 예측값과 실제값의 차이를 줄여나가는 과정을 의미한다.\n",
    "train = tf.train.AdamOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9423cab9",
   "metadata": {},
   "source": [
    "조기 종료는 과대 적합을 피하고 충분한 학습을 하기 위해서 학습 중간마다 검증 데이터에 대한 정확도를 측정하믄 학습 데이터에 대한 정확도는 계속 증가하는 반면에 검증 데이터에 대한 정확도가 점차 떨어지는 경우 학습을 중지하는 것을 말한다.  \n",
    "매 epoch 마다 검증 데이터로 검증 정확도를 측정해서 검증 정확도가 5번 연속으로 검증 정확도의 최대값보다 높지 않을 경우, 조기 종료를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7abdc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver() # 텐서플로우에서 학습 모델의 저장 및 로드에 사용할 변수를 선언한다.\n",
    "epoch_cnt = 300 # 조기 종료가 일어나지 않을 경우 최대 300번까지 반복해서 학습하도록 설정한다.\n",
    "batch_size = 1000 # 1번에 읽어서 처리할 데이터의 개수를 설정한다.\n",
    "iteration = len(x_train) // batch_size # batch_size에 따른 1 epoch당 학습 횟수를 설정한다.\n",
    "earlystop_threshold = 5 # 검증 정확도가 검증 정확도의 최대값보다 5번 연속으로 높지 않을 경우 조기 종료하도록 설정한다.\n",
    "earlystop_cnt = 0 # 검증 정확도가 검증 정확도의 최대값보다 연속으로 높지 않은 검증 횟수를 세는 변수를 선언한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d3e55",
   "metadata": {},
   "source": [
    "학습을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcb5d9ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [10000] vs. [50000]\n\t [[node Equal_1 (defined at <ipython-input-17-9f419d2cbd0c>:22) ]]\n\nOriginal stack trace for 'Equal_1':\n  File \"c:\\python\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\python\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\python\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\python\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\python\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"c:\\python\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"c:\\python\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\python\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\python\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-9f419d2cbd0c>\", line 22, in <module>\n    correct_prediction = tf.equal(tf.argmax(predict, 1), tf.argmax(y, 1))\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1864, in equal\n    return gen_math_ops.equal(x, y, name=name)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3218, in equal\n    name=name)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 750, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3569, in _create_op_internal\n    op_def=op_def)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1359\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1360\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1453\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [10000] vs. [50000]\n\t [[{{node Equal_1}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9f419d2cbd0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Session.run()과 Tensor.eval()의 차이\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# t가 Tensor 오브젝트라면 t.eval()은 sess.run(t)의 속기 표현이다. sess가 현재 디폴트 세션인 곳에서만 가능하다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mcur_train_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m# 검증 정확도 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mcur_val_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    934\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \"\"\"\n\u001b[1;32m--> 936\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdeprecation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Use ref() instead.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   5545\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5546\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 5547\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 968\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    969\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1191\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1192\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1369\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1392\u001b[0m                     \u001b[1;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1394\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [10000] vs. [50000]\n\t [[node Equal_1 (defined at <ipython-input-17-9f419d2cbd0c>:22) ]]\n\nOriginal stack trace for 'Equal_1':\n  File \"c:\\python\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"c:\\python\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"c:\\python\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"c:\\python\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 619, in start\n    self.io_loop.start()\n  File \"c:\\python\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n    self.asyncio_loop.run_forever()\n  File \"c:\\python\\lib\\asyncio\\base_events.py\", line 438, in run_forever\n    self._run_once()\n  File \"c:\\python\\lib\\asyncio\\base_events.py\", line 1451, in _run_once\n    handle._run()\n  File \"c:\\python\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"c:\\python\\lib\\site-packages\\tornado\\ioloop.py\", line 688, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"c:\\python\\lib\\site-packages\\tornado\\ioloop.py\", line 741, in _run_callback\n    ret = callback()\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 814, in inner\n    self.ctx_run(self.run)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 775, in run\n    yielded = self.gen.send(value)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 261, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 234, in wrapper\n    yielded = ctx_run(next, result)\n  File \"c:\\python\\lib\\site-packages\\tornado\\gen.py\", line 162, in _fake_ctx_run\n    return f(*args, **kw)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 302, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"c:\\python\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 539, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2867, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2895, in _run_cell\n    return runner(coro)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3072, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3263, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"c:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-17-9f419d2cbd0c>\", line 22, in <module>\n    correct_prediction = tf.equal(tf.argmax(predict, 1), tf.argmax(y, 1))\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1864, in equal\n    return gen_math_ops.equal(x, y, name=name)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 3218, in equal\n    name=name)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 750, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3569, in _create_op_internal\n    op_def=op_def)\n  File \"c:\\python\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    prev_train_acc = 0.0 # 이전 학습 정확도를 기억할 변수를 선언한다.\n",
    "    max_val_acc = 0.0 # 검증 정확도의 최대값을 기억할 변수를 선언한다.\n",
    "    # 지정한 최대 epoch 만큼 학습한다. => 검증 정확도가 검증 정확도의 최대값보다 5번 연속으로 높지 않을 경우 조기 종료한다.\n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0.0 # 손실값\n",
    "        start = 0 # 학습 시작 위치\n",
    "        end = batch_size # 학습 종료 위치\n",
    "        # 학습 데이터를 batch_size 개 만큼씩 나눠서 학습을 진행한다.\n",
    "        for i in range(iteration):\n",
    "            _, loss_op = sess.run([train, loss], feed_dict={x: x_train[start:end], y: y_train[start:end], keep_prob: 0.9})\n",
    "            # 학습할 데이터의 범위를 batch_size 만큼 이동시킨다.\n",
    "            start += batch_size\n",
    "            end += batch_size\n",
    "            # 크로스 엔트로피 손실 함수의 학습 손실을 계산한다.\n",
    "            avg_loss += loss_op / iteration\n",
    "        # ===== for i\n",
    "        \n",
    "        # 모델 검증\n",
    "        predict = tf.nn.softmax(logits=logit) # 소프트 맥스 적용\n",
    "        correct_prediction = tf.equal(tf.argmax(predict, 1), tf.argmax(y, 1))\n",
    "        \n",
    "        # 정확도 계산\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n",
    "        # 학습 정확도 계산\n",
    "        # Session.run()과 Tensor.eval()의 차이\n",
    "        # t가 Tensor 오브젝트라면 t.eval()은 sess.run(t)의 속기 표현이다. sess가 현재 디폴트 세션인 곳에서만 가능하다.\n",
    "        cur_train_acc = accuracy.eval({x: x_train, y: y_train, keep_prob: 1.0})\n",
    "        # 검증 정확도 계산\n",
    "        cur_val_acc = accuracy.eval({x: x_val, y: y_val, keep_prob: 1.0})\n",
    "        # 학습 정확도와 검증 정확도를 출력한다.\n",
    "        print('epoch: {:3d}, 학습 정확도: {:7.5f}, 검증 정확도: {:7.5f}'.format(epoch, cur_train_acc, cur_val_acc))\n",
    "        \n",
    "    # ===== for epoch\n",
    "# ===== with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01edb436",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc337b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
